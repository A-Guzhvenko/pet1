{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fa4477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import pydub\n",
    "import requests\n",
    "import speech_recognition as sr\n",
    "from bs4 import BeautifulSoup\n",
    "from p_tqdm import p_map\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from seleniumwire import webdriver as wire_webdriver\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from twocaptcha import TwoCaptcha\n",
    "\n",
    "from src.parsing_fun import ProxyRotator, proxy, random_sleep, captcha_bypass, \\\n",
    "    write_audio, audio_to_text, viewbull_field_container, process_page\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c0e79-5158-4721-a68d-e80ae6847cce",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "For Pet project was chosen site farpost.ru with ads for apartments for sale in Primorsky and Khabarovsk regions, at the first stage it is necessary to get a dataset of ads of the site. As an example, the largest cities Amursk, Vladivostok, Nakhodka, Ussuriysk, Khabarovsk, Komsomolsk-Na-Amure and Amursk were chosen.\n",
    "            \n",
    "1) Parsing consists of two stages, the first parses the list of links to ads on the second parses the ads themselves.\n",
    "2) In the process of parsing realized bypass Google captcha (ReCapcha) and text captcha.\n",
    "3) Parsing was performed using paid proxies (proxy6.net).\n",
    "\n",
    "The output is a dataset for further processing in EDA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aecdfdd-d3db-4518-b7eb-36f9addf1619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Audio file used for captcha recognition\n",
    "name_audio_file = \"audio_file.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b21c4e4-8a10-46bd-8ed8-eedee8d10d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of proxies for parsing\n",
    "# (currently not working, if you reuse the code you should replace them with others)\n",
    "proxies = [\n",
    "    {\n",
    "        \"http\": \"socks5://s4PVjF:kcFuTM@147.45.56.125:8000\",\n",
    "        \"https\": \"socks5://s4PVjF:kcFuTM@147.45.56.125:8000\",\n",
    "    },\n",
    "    {\n",
    "        \"http\": \"socks5://s4PVjF:kcFuTM@188.130.203.60:8000\",\n",
    "        \"https\": \"socks5://s4PVjF:kcFuTM@188.130.203.60:8000\",\n",
    "    },\n",
    "    {\n",
    "        \"http\": \"socks5://s4PVjF:kcFuTM@188.130.201.230:8000\",\n",
    "        \"https\": \"socks5://s4PVjF:kcFuTM@188.130.201.230:8000\",\n",
    "    },\n",
    "    {\n",
    "        \"http\": \"socks5://s4PVjF:kcFuTM@188.130.203.175:8000\",\n",
    "        \"https\": \"socks5://s4PVjF:kcFuTM@188.130.203.175:8000\",\n",
    "    },\n",
    "    {\n",
    "        \"http\": \"socks5://QvY0Bz:49N7R7@46.161.45.51:9347\",\n",
    "        \"https\": \"socks5://QvY0Bz:49N7R7@46.161.45.51:9347\",\n",
    "    },\n",
    "    {\n",
    "        \"http\": \"socks5://QvY0Bz:49N7R7@5.8.13.198:9432\",\n",
    "        \"https\": \"socks5://QvY0Bz:49N7R7@5.8.13.198:9432\",\n",
    "    },\n",
    "    {\n",
    "        \"http\": \"socks5://QvY0Bz:49N7R7@188.119.124.55:9663\",\n",
    "        \"https\": \"socks5://QvY0Bz:49N7R7@188.119.124.55:9663\",\n",
    "    },\n",
    "    {\n",
    "        \"http\": \"socks5://QvY0Bz:49N7R7@193.124.179.54:9996\",\n",
    "        \"https\": \"socks5://QvY0Bz:49N7R7@193.124.179.54:9996\",\n",
    "    },\n",
    "]\n",
    "\n",
    "proxy_rotator = ProxyRotator(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e782a791-0d97-418b-8699-53f7c49f6ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First step of parsing, parsing the list of ad links\n",
    "# Browser Options\n",
    "chrome_options = Options()\n",
    "\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "# Run in the background without GUI (can be removed for visual control)\n",
    "\n",
    "chrome_options.add_argument(\n",
    "    \"--disable-blink-features=AutomationControlled\"\n",
    ")  # Hide automation\n",
    "\n",
    "# Add a parameter to not load images\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# Specify the path to ChromeDriver if it is not in the PATH\n",
    "service = Service(executable_path=\"\")\n",
    "\n",
    "# Create an instance of the Chrome browser\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "# A list to store the results\n",
    "results = []\n",
    "href_lists = []\n",
    "\n",
    "\n",
    "cities_lst = [\n",
    "    \"amursk\",\n",
    "    \"vladivostok\",\n",
    "    \"nakhodka\",\n",
    "    \"ussuriisk\",\n",
    "    \"khabarovsk\",\n",
    "    \"komsomolsk-na-amure\",\n",
    "]\n",
    "apartments = [\"share\", \"room\", \"gostinka\",\n",
    "              \"studio\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "\n",
    "for city in cities_lst:\n",
    "    for apartment in apartments:\n",
    "        # Page load\n",
    "        url = f\"https://www.farpost.ru/{city}/realty/sell_flats/?flatType%5B%5D={apartment}\"\n",
    "        driver.get(url)\n",
    "        page_source = driver.page_source\n",
    "        # Random delay after page load\n",
    "        random_sleep(2, 5)\n",
    "\n",
    "        # Create a BeautifulSoup object to parse\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        # Find the item by id and get the data-count value\n",
    "        element = soup.find(\"span\", id=\"itemsCount_placeholder\")\n",
    "\n",
    "        try:\n",
    "            number_links = int(element[\"data-count\"] if element else \"200\")\n",
    "        except Exception as ex:\n",
    "            number_links = 200\n",
    "\n",
    "       # Count the number of pages\n",
    "        number_pages = math.ceil(number_links / 50)\n",
    "\n",
    "        # Cycle to scroll page and collect data\n",
    "        for i in tqdm(range(number_pages)):\n",
    "            # Page load\n",
    "            page = i + 1\n",
    "            url = f\"https://www.farpost.ru/{city}/realty/sell_flats/?flatType%5B%5D={apartment}&page={str(page)}\"\n",
    "            driver.get(url)\n",
    "            page_source = driver.page_source\n",
    "            # Random delay after page load\n",
    "            random_sleep(1, 3)\n",
    "\n",
    "            # Create a BeautifulSoup object to parse\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            # Scroll to the bottom of the page\n",
    "            driver.find_element(\"tag name\", \"body\").send_keys(Keys.END)\n",
    "\n",
    "            # Data collection after scrolling\n",
    "            page_source = driver.page_source\n",
    "\n",
    "            # Create a BeautifulSoup object to parse\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            # Get all <a> tags with data-role=\"bulletin-link\" attribute\n",
    "            bulletin_links = soup.find_all(\n",
    "                \"a\", class_=\"bulletinLink bull-item__self-link auto-shy\"\n",
    "            )\n",
    "\n",
    "            # Create a list of all hrefs\n",
    "            href_list = [link.get(\"href\") for link in bulletin_links]\n",
    "\n",
    "            results.extend(href_list)\n",
    "\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284ad2b-2a03-431d-b216-396a039136d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the process of parsing due to network failures we got 5 files with links\n",
    "# save to df\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# сохраняем в файл\n",
    "df_results.to_csv(\"results5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d14c9-2be5-49c2-ba4e-c8c0e5dd55c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect the links in a dataframe\n",
    "links_1 = pd.read_csv(\"results1.csv\")\n",
    "links_2 = pd.read_csv(\"results2.csv\")\n",
    "links_3 = pd.read_csv(\"results3.csv\")\n",
    "links_4 = pd.read_csv(\"results4.csv\")\n",
    "links_5 = pd.read_csv(\"results5.csv\")\n",
    "\n",
    "data_df_combined = pd.concat(\n",
    "    [links_1, links_2, links_3, links_4, links_5], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a15353-5236-4de8-96e5-64c3f5e80a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete duplicates\n",
    "data_df_combined.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff105517-980e-404f-877a-658609912980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the column after concat\n",
    "data_df_combined.drop(labels=\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35fe85-d36b-4589-bbcf-9e66b3ecb0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove dates where the link was incorrectly sparsed\n",
    "data_df_combined.drop(\n",
    "    data_df_combined[data_df_combined[\"0\"] ==\n",
    "                     \"javascript:void(0)\"].index, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a0ec126-6fc7-433f-8a8f-743160685628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save to file\n",
    "data_df_combined.to_csv(\"links.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4adcc219-a89d-4f3e-aeab-8cfc3b81fbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The second stage of parsing, parsing ads using the received links\n",
    "# Browser options\n",
    "chrome_options = Options()\n",
    "\n",
    "# Run in the background with no GUI (can be removed for visual control)\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "# Hide automation\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "# Disable JavaScript loading\n",
    "chrome_options.add_argument(\"--disable-javascript\")\n",
    "\n",
    "# Specify the path to ChromeDriver if it is not in the PATH\n",
    "service = Service(executable_path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721807cc-c7a4-45c7-a289-1fb00f0f184b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_links = len(data_df_combined)\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "for i in tqdm(range(17640, number_links)):\n",
    "    \n",
    "    url = f\"{data_df_combined.iloc[i,0]}\"\n",
    "   \n",
    "    driver.get(url)\n",
    "    page_source = driver.page_source\n",
    "  \n",
    "    # Create a BeautifulSoup object to parse\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Check condition 1: The captcha is simple\n",
    "    captcha_element = soup.find(\"h2\", string=\"Вы не робот?\")\n",
    "    img_tag = soup.find(\"img\", {\"alt\": \"Изображение для проверки\"})\n",
    "\n",
    "    if captcha_element is not None and img_tag is not None:\n",
    "        #print(f\"Requires entering a simple captcha, ad №{i}\")\n",
    "        \n",
    "        закрываем драйвер\n",
    "        driver.quit()\n",
    "        \n",
    "        меняем прокси\n",
    "        driver = proxy()\n",
    "        \n",
    "        # reload the page\n",
    "        driver.get(url)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "        \n",
    "        process_page(soup, i, data_df_combined)\n",
    "        continue\n",
    "\n",
    "    # Check Condition 2: Google Captcha\n",
    "    elif captcha_element is not None:\n",
    "        print(f\"Need google captcha processing, ad №{i}\")\n",
    "        # Call the function to process the Google captcha\n",
    "        driver = captcha_bypass(driver)\n",
    "        driver.get(url)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "        process_page(soup, i, data_df_combined)\n",
    "        continue\n",
    "        \n",
    "    # All right, parse the page.\n",
    "    process_page(soup, i, data_df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "edc7417d-68f5-451e-8c58-be3e7d08a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the resulting dataset to a file\n",
    "data_df_combined.to_csv(\"data/data.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e57320-5f64-4849-9890-f76a3eac63eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
